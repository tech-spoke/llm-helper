# Speed Improvement Plan - Critical Review

## ⚠️ 重大な問題点

### 1. Phase 1: シンボルインデックスの根本的欠陥

#### 問題1.1: 部分一致検索との非互換性
```python
# 現在の実装
if symbol.lower() in tag_name.lower():  # 部分一致
```

**問題**:
- インデックスは完全一致しか効率化できない
- "Auth" で検索 → "AuthService", "AuthController", "authenticate" 全部ヒット
- 結局**全シンボルをスキャン**する必要がある
- **インデックスの意味がない**

**影響**: Phase 1の95%削減効果は**達成不可能**

#### 問題1.2: 同名シンボルの大量ヒット
```python
"user": {
    "files": ["models/User.php", "controllers/UserController.php",
              "views/user.blade.php", "tests/UserTest.php", ...]
}
```

**問題**:
- よくある名前（user, id, name, data）は数百ファイルでヒット
- 結局O(該当ファイル数) = O(n)
- **インデックスによる高速化はほぼゼロ**

#### 問題1.3: インデックスサイズの爆発
- 10,000ファイル × 平均100シンボル = **100万エントリ**
- JSON形式で**50-200MB**
- メモリ消費が大きすぎる
- ディスクI/Oで逆に遅くなる可能性

---

### 2. Phase 2: 並列処理の誤解

#### 問題2.1: I/Oバウンドの誤認識
```python
# 想定: I/O待ちで並列化効果大
# 実際: ctagsはCPUバウンド（パース処理）
```

**実測データ（推定）**:
- ファイル読み込み: 1ms（OSキャッシュ済み）
- ctagsパース: 10-50ms（CPU処理）

**結果**:
- 並列化しても**CPUコア数が上限**
- 4コアなら4倍、8コアなら8倍が限界
- 期待した50%削減は**過大評価**（せいぜい25-30%）

#### 問題2.2: タスク生成オーバーヘッド
```python
tasks = [scan_file(f) for f in files]  # 1000ファイル = 1000タスク
```

- asyncioタスク生成コスト
- メモリ消費
- スケジューラ負荷

**小規模プロジェクトでは逆に遅くなる**

---

### 3. Phase 3: 増分更新の実装困難性

#### 問題3.1: MCPサーバーの性質
```
MCPサーバー = 都度起動型
├─ セッション開始 → プロセス起動
├─ ツール実行
└─ セッション終了 → プロセス終了
```

**問題**:
- ファイル監視デーモンは**実装不可能**
- 常駐プロセスではない
- Watchdogは使えない

#### 問題3.2: Git依存の脆弱性
```python
def get_project_hash():
    return subprocess.run(["git", "rev-parse", "HEAD"])
```

**問題**:
- 非Gitプロジェクトは？
- 作業ツリーの変更を検知できない（コミット前）
- Git外のファイル変更は検知不可

**致命的**: 開発中は常にコミット前なので**増分更新が動作しない**

---

### 4. Phase 4: 参照検索の曖昧性

#### 問題4.1: 動的言語の限界
```php
// PHP例
$method = 'login';
$obj->$method();  // 動的呼び出し

// JavaScript例
const obj = {};
obj[computedKey] = value;
```

**問題**:
- 静的解析では検知不可能
- 正確性が保証できない
- **偽陰性（見逃し）が多発**

#### 問題4.2: コメント・文字列の扱い
```php
// "login" という文字列が出現
$comment = "Call login() to authenticate";
```

これは参照？単なる文字列？

---

## 🚨 実装時間の過小評価

### Phase 1: 「3-4時間」→ **実際は2-3週間**

**理由**:
- インデックス構造の再設計（部分一致対応）
- Trie木またはサフィックスツリーの実装
- メモリ効率化（圧縮）
- 並行更新の排他制御
- エッジケース対応（シンボリックリンク、巨大ファイル）
- テストケース作成
- パフォーマンス計測・チューニング

### Phase 2: 「1-2時間」→ **実際は1週間**

**理由**:
- 最適並列数の実測
- CPU/IOバウンドの判定
- デッドロック対策
- エラー伝播の処理
- タイムアウト処理
- ベンチマーク作成

---

## 📊 パフォーマンス見積もりの根拠不足

### 主張: 「2-3分 → 0.5秒」
### 問題: **根拠となる実測データなし**

必要な検証:
- プロジェクトサイズ別（100, 1000, 10000ファイル）
- 言語別（Python, PHP, JavaScript）
- シンボル名の出現頻度別
- キャッシュヒット率の実測

**現状**: 希望的観測のみ

---

## 🔍 Cursorとの比較の誤り

### Cursorの実装
```
Cursor = 常駐型エディタ + インメモリインデックス
├─ プロセス起動: 1回のみ（エディタ起動時）
├─ インデックス: メモリ常駐
├─ 更新: バックグラウンドスレッド
└─ 検索: O(1) ハッシュテーブル
```

### このMCPサーバー
```
MCP = 都度起動型 + ディスクキャッシュ
├─ プロセス起動: 毎回
├─ インデックス: ディスクから読み込み
├─ 更新: 同期実行
└─ 検索: O(log n) または O(n)
```

**結論**: **同じ土俵で比較できない**

---

## ✅ 代替案の提案

### A. 短期的（今すぐ使える）

#### A1. `--fast` のデフォルト化オプション
```bash
# .code-intel/config.yml
default_gate_level: "none"  # --fastをデフォルトに
```

**効果**: 即座に0秒でREADY

#### A2. `--gate=low` の積極的推奨
- ドキュメント更新
- `/code` スキルでデフォルト推奨

**効果**: 2-3分削減

---

### B. 中期的（実装2-3週間）

#### B1. sqlite3ベースのインデックス
```sql
-- シンボルテーブル
CREATE TABLE symbols (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    file_path TEXT NOT NULL,
    line INTEGER,
    kind TEXT
);

-- 部分一致検索用インデックス
CREATE INDEX idx_symbols_name ON symbols(name);
CREATE INDEX idx_symbols_name_prefix ON symbols(name COLLATE NOCASE);

-- Trigram インデックスで部分一致高速化
CREATE VIRTUAL TABLE symbols_fts USING fts5(name, file_path);
```

**メリット**:
- 部分一致検索が高速（FTS5）
- トランザクションで整合性保証
- メモリ効率的
- 圧縮可能

**実装時間**: 2-3週間

#### B2. 並列処理の慎重な実装
```python
import multiprocessing

# CPU数を取得
cpu_count = multiprocessing.cpu_count()

# 並列数 = CPU数 * 0.8（余裕を持たせる）
max_workers = max(1, int(cpu_count * 0.8))

# ProcessPoolExecutor で並列化（asyncioより効率的）
with ProcessPoolExecutor(max_workers=max_workers) as executor:
    results = executor.map(scan_file, files)
```

**実装時間**: 1週間

---

### C. 長期的（実装1-2ヶ月）

#### C1. LSP統合
- エディタのLSPサーバーを活用
- TypeScript/Python/PHPのLSPと連携
- インデックス構築不要

#### C2. 常駐型インデックスサーバー
- 独立したデーモンプロセス
- MCPサーバーはクライアントとして接続
- ファイル監視 + 自動更新

---

## 📋 推奨される実装順序

### フェーズ1: 即効性のある改善（今週）
1. ドキュメント更新（`--fast`, `--gate=low`の推奨）
2. デフォルトgate levelの設定可能化

**期待効果**: ユーザーが意識的に高速化を選択可能

### フェーズ2: 並列処理の実装（来週）
1. ProcessPoolExecutorによる並列化
2. 最適並列数の自動決定
3. ベンチマーク作成

**期待効果**: 20-30%高速化（控えめ）

### フェーズ3: sqlite3インデックス（1ヶ月後）
1. データベーススキーマ設計
2. FTS5による部分一致検索
3. 増分更新ロジック
4. パフォーマンステスト

**期待効果**: 50-70%高速化（実測ベース）

---

## 結論

### 元のプランの問題点まとめ
1. ❌ Phase 1の95%削減は**非現実的**（部分一致との非互換）
2. ❌ Phase 2の50%削減は**過大評価**（CPU バウンド）
3. ❌ Phase 3の増分更新は**実装不可能**（都度起動型）
4. ❌ 実装時間が**10倍過小評価**
5. ❌ パフォーマンス見積もりに**根拠なし**

### 修正版プランの特徴
1. ✅ 実装可能性を重視
2. ✅ 段階的アプローチ
3. ✅ 控えめな効果予測
4. ✅ 実装時間の現実的見積もり
5. ✅ 代替技術の検討

### 最終推奨
**短期的には `--fast` / `--gate=low` の積極活用**
**中長期的には sqlite3 インデックス + 並列処理**

Cursor並みの30秒を目指すなら、**常駐型サーバーへの移行が必須**
